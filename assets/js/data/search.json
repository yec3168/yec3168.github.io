[ { "title": "nodejs GET, POST", "url": "/posts/nodejs_basis2/", "categories": "Node.js, basis", "tags": "nodejs, 백엔드, 기초", "date": "2023-08-03 00:00:00 +0900", "snippet": "Get 요청app.get('/', (req, res) =&gt; { res.send('Hello World!')})위 코드처럼 주소창에서 데이터를 같이 넘기는 방식.(localhost:3000같은 주소창으로 접근 )위와 같은 형태로 콜백함수에 전달된 req객체를 이용하면 get 방식으로 요청이 들어오면 데이터를 가져와서 html 파일에 적용할 수 있다. req : requestres : responsequery, 파라미터 값으로 라우팅 파라미터 app.get('/user/:id', (req, res) =&gt; { //파라미터 const p = req.params; console.log(p) res.json({'userid': p.id}) //res가 응답으로 \"send('Hello World!')\"을 보내줌.})req는 요청할때 넣는 정보를 가지고 있다. 사용하는 방식이 get방식이 때문에 주소창에다가 ID값을 입력해서 전달한다.console.log로 params를 출력하면 아래와 같은 결과가 나온다. query app.get('/user/:id', (req, res) =&gt; { //파라미터 const q = req.query; console.log(q) res.json( { 'userQ': q.q, 'userName' : q.name } ) //res가 응답으로 \"send('Hello World!')\"을 보내줌.})query를 보낼때 주소창에 localhost:3000/user/IDSetting?q=ec&amp;name=eungchan처럼 보낸다. ?뒤에 보낼 정보들을 입력하는데 요청으로 보낼때 알맞는 값들을 &amp;문자로 구분하여 값을 넣어주며 request한다.위 사진처럼 id값과 q, name값을 입력하게 되면 결과값이 나온다. url에 한글 즉 /강아지, /고양이같은 방식은 안된다. url은 아스키문자이기때문에 한글을 지원하지 않는데, 한글을 url에 쓰고 싶다면 따로 URL/ Decoder/Encoder에 접속해서 나오는 문자를 입력하면 된다.Post 요청주소창이 아니라 내부적으로 body에 데이터를 전달한다.나중에 더 자세히 알아보자" }, { "title": "nodejs 1일차", "url": "/posts/nodejs_basis/", "categories": "Node.js, basis", "tags": "nodejs, 백엔드, 기초", "date": "2023-07-28 00:00:00 +0900", "snippet": "information주변에서 말하길 배워두면 써먹을 곳이 많은 언어중 하나이다. 남들이 다 추천하면서 꼭 배워두는것이 좋다고 말하여 나도 한번 공부해보자고 생각해서 시작한다.Node.jsNode.js는 내 컴퓨터 혹은 서버에서 돌리는 백엔드이다. 자바스크립트를 이용하여 만들고, npm이라는 언어를 사용하여 모듈을 가져와서 조합해서 사용한다고 한다.기존의 자바스크립트는 브라우저를 통해 실행하였는데 nodejs를 사용하면 따로 브라우저 없이도 실행이 가능하다.Install Node.jsNode.js에 들어가 안정적, 신뢰도 높은이 적혀있는 버전을 다운받자.설치가 완료되면 Visual Studio Code를 열어 자신이 원하는 위치에 폴더 하나를 생성하자.index.js파일을 만들자.Hello World출력 연습을 해보자. 만들어진 index.js 파일에 아래 코드를 입력하자. console.log(\"hello world\")Visual studio code에서 새 터미널을 열고 Node 명령어를 사용해서 index.js 파일을 실행하자. node index.jsnpmnpm는 Node package manager의 약자로 모든 코드를 직접짜지 않고, 여기서 필요한 모듈을 검색해서 다운받아서 사용하는 것이다.window에서 exe 파일을 통해 설치하는 것처럼 node.js에서 모듈을 설치할때는 터미널을 이용하여 아래 명령어를 통해 필요 모듈을 설치한다. npm install [모듈이름] -g 라는 속성을 주게 되면 해당폴더말고도 다른 모든 폴더에서도 다운받은 모듈을 사용할 수 있다.figletnpm 홈페이지에 figlet을 검색해서 모듈을 다운받자. figlet은 아스키 art를 만들어주는 모듈.터미널에 npm install figlet을 입력해 figlet모듈을 다운받자. var figlet = require(\"figlet\"); figlet(\"Hello World!!\", function (err, data) { if (err) { console.log(\"Something went wrong...\"); console.dir(err); return; } console.log(data);});위 코드는 figlet 모듈 배포사이트에 있는 예시문으로 hello world를 아스키 art로 만들어준다. package-lock: 생성된 package의 정보를 더 구체적으로 알려주는 파일.Express 모듈node.js를 이용해서 웹 프레임워크를 만드는 것이다. 웹 프레임워크 : 웹의 프론트엔드에서 무언가 클릭했을때 백엔드로 요청을 보내 백엔드에서 요청에 대한 응답을 보내주는 역할.설치npm i express위 명령어로 express 설치.const express = require('express') //const app = express()const port = 3000// get : http 메소드// '/' : 라우팅// ()=&gt;{} : 콜백 함수app.get('/', (req, res) =&gt; { res.send('Hello World!') //res가 응답으로 \"send('Hello World!')\"을 보내줌.})// port : 들어오는 입구// ()는 함수app.listen(port, () =&gt; { console.log(`Example app listening on port ${port}`)})simple 코드를 입력하고 index.js파일을 실행하면 localhost:3000에 접속할 수 있다." }, { "title": "정보처리기사 실기 공부 2", "url": "/posts/license2/", "categories": "license, 정처기", "tags": "license, Engineer Information Processing", "date": "2023-07-09 00:00:00 +0900", "snippet": "데이터베이스데이터 저장소, 데이터베이스 , DBMS 데이터 저장소 데이터를 논리적인 구조로 조직화 하거나, 물리적인 공간에 구축한 것을 의미 데이터 베이스 공동으로 사용될 데이터를 중복을 배제하여 통합 데이터를 저장장치에 저장하는 것 DBMS 데이테베이스를 관리해주는 소프트웨어 정의, 조작, 제어 기능이 존재 스키마 데이터베이스의 구조와 제약조건을 기술한 것. 외부스키마 사용자나 프로그래머의 입장에서 데이터 베이스의 논리적 구조를 정의한 것 개념 스키마 데이터 베이스의 논리적 구조 내부 스키마 물리적 장치 입장에서 본 데이터 베이스의 구조데이터베이스 설계데이터베이스는 무결성, 일관성, 회복, 보안 ,효율성, 데이터베이스 확장을 고려해서 작성해야함.설계 순서요구조건분석 &gt; 개념적 설계 &gt; 논리적 설계 &gt; 물리적 설계 &gt; 구현 요구조건 분석 데이터베이스의 필요용도 파악, 요구조건 명세 작성 개념적 설계 개념 스키마 모델링, ER 모델링 수행. 논리적 설계 논리적스키마, 인터페이스 설계 DBMS가 지원하는 논리적 자료구조로 벼환 물리적 설계 물리적스키마, 논리적설계로 표현된 데이터를 물리적 구조의 데이터로 변환하는 과정 데이터베이스 관계개체와 개체 사이의 논리적인 연결 데이터베이스와 데이터베이스사이의 관계. 종속관계 식별과 비식별 관계 중복관계 두 개체 사이의 두번 이상 종속관계가 발생한는 관계 재귀관계 개체가 자기자신과 관계를 갖음. 베타 관계 개체가 속성이나 구분자를 기준으로 개체의 특성을 분할하는 관계, AND, OR 키 후보키 유일하게 식별하기 위해 사용되는 속성의 부분집합 유일성, 최소성 기본키 후보키중 선정된 키 대체키 후보키중 기본키를 제외한 나머지 키 슈퍼키 유일성은 만족하지만 최소성은 x 속성의 잡합으로 구성된 키 외래키 다른 릴레이션을 참조하는 속성 무결성데이터베이스에 저장된 값과 현실세계의 값이 일치하는 정확성 개체 무결성 기본키를 구성하는 어떤 속성도 NULL을 가질수 없음 참조 무결성 외래키 값은 NULL일수 있음 도메인 무결성 주어진 값이 도메인(속성의 정해진 값)에 속해야함. 이상테이블에서 문제가 발생하는 현상 삽입 이상 원하지 않는 값들로 인해 삽입이 되는 현상 삭제 이상 연쇄 삭제가 발생 갱신 이상 갱신의 실수로 정보에 불일치 발생 정규화 제 1정규화 도메인의 원자성 제 2정규화 제 1정규화를 만족한 테이블의 부분 함수 종속을 제거 제 3정규화 제 2정규화를 만족한 테이블의 이행적 함수 종속 제거 BCNF 결정자이면서 후보키가 아닌 것을 제거 제 4정규화 다치 종속 제거 제 5정규화 후보키를 통하지 않는 조인 종속 제거 트랜잭션 한꺼번에 모두 수행되어야할 일련의 연산 원자성, 일관성, 독립성, 영속성CRUDCreate, Read, Update, Delete를 이용하여 트랜잭션을 분석하는 것.클러스터 / 파티션 클러스터 동일한 성격을 가진 데이터들을 블럭으로 묶어서 저장하는 방법 파티션 대용량의 테이블이나 인덱스를 작은 논리적인 단위인 파티션으로 나누는 것. 범위 분할 : 지정된 열의 값을 기준으로 분할 해시 분할 : 해시함수를 적용하여 분할 조합 분할 : 범위 분할 후 해시함수를 적용. 분산데이터베이스하나의 시스템을 여러 공간에 나누어 저장하는 데이터 베이스. 위치투명성 : 실제 위치를 알 필요 없음. 중복투명성 : 실제로 중복이 존재해도 하나의 데이터만 존재한다고 사용자는 인식함. 병행투명성 : 다수의 트랜잭션이 동시에 실현되도 결과는 투명 장애투명성RTO (Recovery time objective)/ RPO(Recovery point objective) RTO 복구되어 다시 가동할때까지 소요시간 RPO 데이터를 복구할 수 있는 기준점 DDL, DML, DCL DDL Create, Alter, Drop DML Select, insert, delete, update DCL Grant revoke, rollback, commit 프로그래밍정렬|정렬|시간복잡도| |–|–| |삽입정렬, 선택정렬, 버블정렬| o(n^2)| |퀵정렬, 힙정렬|o(nlog2n)|트리 디그리 -각 노드에서 뻗어나온 가지 수 차수 노드중 디그리가 가장많은 수 «««&lt; HEAD 556b15ccf837a943e5c54149cb34497d44fad17d " }, { "title": "정보처리기사 실기 공부 1", "url": "/posts/license1/", "categories": "license, 정처기", "tags": "license, Engineer Information Processing", "date": "2023-07-05 00:00:00 +0900", "snippet": "소프트웨어 설계요구사항 분석 소프트웨어 생명주기 (Software development life cycle) 시스템의 요구분석 부터 유지보수까지 모든 부분을 체계화한 절차. 단계별로 정리.1. 요구사항 분석(명세화)요구사항을 결정하는 단계, 실제 사용자와 함께 정의하는 단계4. 테스트(시험)화이트 박스 모듈의 코드를 오픈시킨 상태에서 원스코드의 논리적인 모든경로를 테스트 하는 방법 모든 문장을 한 번 이상 실행함. 기초경로검사(Base Path Testing), 제어 구조검사(Control Structure Testing) 문장검증기준, 분기검증기준, 조건검증기준, 분기/조건기준블랙박스 블랙박스 테스트는 각 기능이 완전히 작동하는 것을 입증하는 테스트 인터페이스에 서 실시되는 테스트애플리케이션 테스트 종류 단위테스트 사용자 요구사항을 테스트하는 단계 자료구조테스트, 실행결로테스트, 오류처리테스트 통합테스트 단위테스트를 통과한 모듈 사이의 인터페이스 상향식테스트, 하향식테스트 시스템테스트 통합된 단위 시스템이 정상적으로 작동하는지 테스트 기능-비기능 요구사항테스트 인수테스트 계약상의 요구사항이 만족되었는지 확인 알파-베타테스트 단.통.시.인 으로 외우자.생명주기 모델 종류 폭포수 모델 ( Waterfall Model ) 각 단계를 확실히 마무리 하고 넘어감. 고전적 생명주기 모형이라고 함. 요구사항 변경이 어렵다. 프로토타입 모델 ( Prototyping Model ) 고객이 요구한 주요 기능을 프로토타입으로 구현. 고객의 피드백을 반영하여 소프트웨어를 만들어감. 나선형 모델( Spiral Model) 위험을 최소화 할 때까지 점진적으로 완벽하게 진행하는 시스템 계획 및 정의 -&gt; 위험분석 -&gt; 개발 -&gt; 고객평가. 반복적 모델 대상을 나누어 병렬적으로 개발 후 통합. 애자일 모형고객의 요구사항 변화에 유연하게 대응할 수 있도록 일정한 주기를 반복하면서 개발과정을 진행. 도구보단 개인과 상호작용 문서보단 실행되는 SW 계약협상보단 고객과의 협업 계획을 따르기 보다는 변화에 반응스크럼 XP(eXtreme Programming) 고객의 요구사항을 유연하게 대처하기 위해 고객의 참여와 개발과정을 반복적으로 수행. 의사소통, 용기, 존중, 피드백, 단순성 의용조피단 DBMS 사용자와 데이터베이스 사이에 존재하며 데이터베이스를 관리해주는 소프트웨어. 가용성, 성능, 기술지원, 상호호환성, 구축비용.WAS (Web Application Server) 웹 어플리케이션 서버로 동적인 컨탠츠를 처리하는 미들웨어 Tomcat, GlassFish, JBoss, Jetty, JEUS, webSphere요구사항 유형 기능 요구사항 시스템이 제공하는 기능 기능성, 완전성, 일관성 비기능 요구사항 시스템장비 구성 요구사항 : 하드웨어, 소프트웨어 등 장비구성에 대한 요구사항. 성능 요구사항 : 처리속도 및 시간, 처리량 요구사항. 시스템이 수행하는 기능 이외의 사항, 제약사항에 관한 요구사항 신뢰성, 사용성, 효율성, 유지보수성, 이식성, 보안성 기능-비기능은 시험에 자주 나오는거 같음요구사항 개발 프로세스 요구사항 도출 요구사항을 식별하고 이해하는 과정 소프트웨어 생명주기를 반복 요구사항 분석 요구사항의 타당성을 조사. (비용, 일정) UML, 자료흐름도(DFD), 자료사전(DD) 등 자료사전CASE (자동화 도구)요구사항 분석을 위한 자동화 도구. SADT(Structured Analysis and Design Technique) SREM RSL REVS 요구사항 명세 정형 명세 기법 비정형 명세 기법 수학 상태/기능/객체 수학적 기호, 정형적 자연어 기반 서술 요구사항을 간결하게 표현 자연어때문에 요구사항결과가 작성자에따라 다를수 있음. 요구사항 확인HIPO 시스템 실행 과정인 입력처리와 출력의 기능을 표현 하향식 소프트웨어 개발을 위한 문서. 가시적 도포 -&gt; 총제적 도포 -&gt; 세부적 도포.UML(Unified Modeling Language) 시스템 개발자와 고객, 개발자와 개발자 간의 의사소통이 원할하게 이루어지도록 표준화한 대표적인 객체지향 모델링 언어관계 연관 관계 집합 관계 포함 관계 일반화 관계 의존 관계 연관은 있으나 필요에 의해 서로에게 영향을 주는 짧은시간에만 유지. 실제화 관계다이어그램 구조적 다이어그램 정적모델링 클래스 다이어그램 객체 다이어그램 럼바우 객체지향 분석. 컴포넌트 다이어그램 배치 다이어그램 복합체 구조 다이어 그램 패키지 다이어그램. 럼바우 분석기법 객체 -&gt; 동적 -&gt; 기능 행위 다이어그램 동적모델링 유스케이스 다이어그램. 순차 다이어그램. 커뮤니케이션 다이어그램. 상태 다이어그램. 활동 다이어그램. 상호작용 다이어그램. 타이밍 다이어그램. 유스케이스 다이어그램 유스케이스란 사용자관점으로 시스템이 액터에게 제공하는 서비스로 사용자 요구를 분석하는 것으로 기능 모델링 작업에 사용. 클래스 다이어그램시스템 구성하는 클래스와 다른 클래스 사이의 관계를 표현. 순차(시퀀스) 다이어그램. 시스템이나 객체들이 메세지를 주고받으며 시간의 흐름에 따라 상호작용하는것을 그림으로 표현한 것.UI CLI(command line interface) 명령과 출력이 텍스트 형태 GUI(Graphical User Interface) 아이콘이나 메뉴를 마우스로 선택하여 작업을 수행 NUI(Natural user interface) 자연스럽게 사용자의 말이나 행동으로 기기를 조작. VUI(Voice user interface) 사람의 음성으로 기기를 조작 OUI(Organic user interface) 모든 사물과 사용자간의 상호작용을 위한 인터페이스 직관성, 유효성(목적이 정확), 학습성, 유연성객체지향 설계 원칙 단일 책임 원칙(SRP) 객체는 단 하나의 책임만 가져야함. 개방 폐쇄 원칙(OCP) 기존의 코드를 변경하지 않고, 기능을 추가. 리스코프 치환(LSP) 자식클래스는 최소한 자신의 부모 클래스에서 기능한 행위는 수행할 수있어야함. 인터페이스 분리(ISP) 자신이 사용하지 않는 인터페이스와 의존관계를 맺거나 영향을 받지 않아야한다. 의존 역전 원칙(DIP) 각 객체들 간의 의존관계가 성립될 때, 추상성이 낮은 클래스보다 높은 클래스에 의존관계를 맺어야함. 결합도모듈간에 상호 의존하는 정도.디자인패턴생성패턴 추상팩토리 빌더 팩토리메소드 프로토타입 싱글톤구조 패턴 어댑터 브리지 컴포지트 데코레이터 퍼싸드 플라이웨이트 프록시행위 패턴 책임연쇄 커맨드 인터프리터 반복자 중재자 머멘토 옵서버 상태 전략 템플릿 메소드 방문자요구사항 검증 방법 동료검토 요구사항 명세서 작성자가 명세서 내용을 직접설명하여 동료들이 이를 들으면서 결함을 발견. 워크스루 요구사항 명세서를 미리 배포하여 검토후, 짧은 검토 회의를 통해 결함을 발견 인스펙션 작성자를 제외한 다른 검토 전문가들이 요구사항 명세서를 확인하면서 결함 프로토타이핑 프로토타입을 만들어 최종 결과물 예측 테스트 설계 테스트 케이스를 생성하여 이후에 요구사항이 현실적으로 테스트 가능한지를 검토 CASE 도구 일관성 분석을 통해 요구사항 변경사항의 추적 및 분석 관리. " }, { "title": "Data Analysis 2(API)", "url": "/posts/Data_analysis2/", "categories": "Data_Analysis, basis", "tags": "Data Analysis, API", "date": "2023-07-04 00:00:00 +0900", "snippet": "API 인증된 URL만 있으면 언제든지 필요한 데이터에 접근할 수 있는 방식. 보통 CSV, JSON, XML을 사용한다.JSON파이썬의 Dictionary + List 해놓은 것d ={\"name\": \"Eungchan\", \"age\": \"25\"}print(d[\"age\"])-&gt; 25json.dumps()파이썬의 json패키지를 사용해서 dictionary를 json형식에 맞는 문자열로 바꿔줌.아까만든 dictionary인 d를 JSON 형식에 맞는 문자열로 변환해보자. json 패키지 importimport json json.dumps사용d_str = json.dumps(d, ensure_ascii = False)print(d_str)-&gt; {“name”: “Eungchan”, “age”: “25”}결과 처럼 JSON형식의 문자열이 된 것을 볼 수 있다. ensure_ascii를 False로 한 이유는 json은 아스키코드값만 출력하기 때문에 한글이 제대로 보이지 않는다. ensure_ascii값을 False로 준다면, 원래 저장된 문자 그대로 출력하게 해준다.type &amp;&amp; json.loadsprint(type(d_str))-&gt; &lt;class ‘str’&gt;type을 보니 str로 문자열이 된 것을 볼 수 있다.load_str = json.loads(d_str)print(load_str[\"name\"])-&gt; Eungchanjson.loads를 이용하여 d_str문자열을 다시 dictionary형태로 바꿀 수 있다.print(type(load_str))-&gt; &lt;class ‘dict’&gt;Codedictionary를 만들고 json.dumps를 사용해서 문자열로 바꾸고 다시 json.load로 바꾸니 굉장히 복잡하니 json 문자열을 바로 json.loads에 전달해보자.d_str2 = json.loads('{\"name\": \"Eungchan\", \"age\" : 25}')print(d_str2[\"name\"])print(d_str2[\"age\"])-&gt; Eungchan 25JSON 배열세겹따옴표(\"\"\")를 사용해서 여러 줄에 걸친 문자열을 만들 수 있다.d_str3 = \"\"\"[ {\"name\": \"Eungchan\", \"age\" : 25}, {\"name\": \"Data\", \"age\" : 99}]\"\"\"d4 = json.loads(d_str3)print(d4[1][\"name\"])-&gt; DataJSON -&gt; DataFrame (pd.read_json)import pandas as pddf2 = pd.read_json(d_str3)df2.head(2)XML&lt;book&gt; &lt;name&gt;혼자 공부하는 데이터분석&lt;/name&gt; &lt;author&gt;박해선&lt;/author&gt;&lt;/book&gt;계층 구조를 이루면서 정보를 표현한다. 시작 태그와 종료 태그로 감싼다.XML을 python으로 표현xml_str =\"\"\"&lt;book&gt; &lt;name&gt;혼자 공부하는 데이터분석&lt;/name&gt; &lt;author&gt;박해선&lt;/author&gt;&lt;/book&gt;\"\"\"XML 패키지 &amp;&amp; fromstringimport xml.etree.ElementTree as etbook = et.fromstring(xml_str)print(book)fromstring으로 ElementTree 객체를 반환한다.부모 element (tag) &amp;&amp; 자식 element(findtext)print(book.tag)-&gt; bookbook_childs = list(book)print(book_childs)-&gt; [&lt;Element ‘name’ at 0x0000019D006B7770&gt;, &lt;Element ‘author’ at 0x0000019D006B7CC0&gt;]데이터 찾기정보나루에 들어가서 API를 다운받기 위해 인증키 신청을 해보자.회원가입하고 원하는" }, { "title": "Data Analysis 1", "url": "/posts/Data_analysis/", "categories": "Data_Analysis, basis", "tags": "Data Analysis, encoding, chardet", "date": "2023-07-04 00:00:00 +0900", "snippet": "Information시작하기 앞서 혼자 공부하는 데이터분석책을 보고 공부했습니다.목표로는 이 책을 어느정도 공부하면서 스스로 데이터를 찾아서 분석해보는것으로 세우고 시작하겠습니다.데이터 분석(Data Analysis)데이터 분석은 단순히 한 마디로 정의하기는 어렵다. 물론 사전적인 의미로는 데이터는 자료, 정보를 의미하고 분석은 복자한 대상을 정확하게 이해하기위해 단순한 요소로 나누어 설명하는것을 의미하게 된다.위키피디아에서 정의된 데이터 분석은 유용한 정보를 발견하고 결론을 유추하거나, 의사 결정을 돕기 위해 데이터를 조사, 정제, 변환하여 모델링 하는 과정을 말한다.데이터 분석과 함께 자주 언급되는 용어에는 데이터 과학이다. 보통은 데이터 분석과 데이터 과학은 동일시 취급되지만, 정확히는 데이터 과학은 통계학, 머신러닝, 데이터마이닝등 같은 큰 개념으로 이루어져있다.데이터 과학(Data Science)데이터 과학자 지 리가 말하길 데이터 과학은 데이터 세계와 비즈니스 세계를 이어주는 다리 역할이다. 데이터 과학을 통해 소프트웨어나 제품은 개발할 수 있지만 이것이 전부가 아니며, 머신러닝, 통계학, 그래프 그리기 등 많은 것을 포함하는 분야이다. 데이터 분석 올바른 의사결정을 돕기위한 통찰에 집중함 데이터 과학 한 걸음 더나아가 문제 해결을 돕기아한 최선의 솔루션을 제공해준다. 언어데이터 분석에 사용되는 언어는 Python, R 이다. 물론 데이터가 데이터베이스 형태로 존재한다면, SQL도 사용할 수 있지만 SQL은 시각화나 통계적인 분석에 어려움이 존재한다.이 책에서 사용되는 언어는 Python이며, 사용되는 프로그램은 구글 Colab을 사용하지만 Visual studio Code가 편하기에 Code로 사용하기로 한다.환경만들기Visual Studio Code홈페이지에 들어가면 아래와 같은 사진이 나와 다운로드를 눌러 설치를 진행하면된다.제대로 다운이 완료되고 실행시켜보면 사진처럼 나오게 된다.여기서 폴더열기를 누르고 C:\\Users\\사용자 이름\\Documents\\위치에 Data_Analysis라는 새로운 폴더를 만들고 폴더 선택을 누르면 된다.무사히 마치면 확장으로 들어가 마켓플레이스에서 python을 설치하자 가장 최신버전으로 설치하면된다.데이터 세트 받아오기폴더를 생성했으면 데이터 분석에 사용할 데이터를 받아와야한다. 책에서 사용하는 데이터 세트는 정보나루에 있는 서울특별시교육청남산도서관 장서/대출 데이터이다.위 사진처럼 데이터 제공에 들어가 검색창에 남산 검색하고 해당 데이터를 CSV형태로 다운받자.다운받은 파일은 이전에 만들었던 Data_Analysis폴더에 넣자. 더 많은 데이터들을 찾고 싶다면 공개 데이터 세트 참고.명령어이제 Data_Analysis폴더에 파일을 하나 만들어보자. 이름은 test.ipynb로해서 만들면 된다.open()CSV 파일은 텍스트 파일이므로 open()함수를 통해 읽을 수 있다.with open('./data/서울특별시교육청남산도서관 장서 대출목록 (2023년 06월).csv') as f: print(f.readline())open 파일은 UTF-8 형식으로 저장되어있다고 가정하지만, 다운받은 CSV 파일의 인코딩 방식이 다른거 같다.chardet_detect()chardet 패키지의 chardet_detect()함수는 파일의 인코딩 방식을 확인한다.import chardetwith open('./data/서울특별시교육청남산도서관 장서 대출목록 (2023년 06월).csv', mode='rb') as f: d = f.readline()print(chardet.detect(d))-&gt; {‘encoding’: ‘EUC-KR’, ‘confidence’: 0.99, ‘language’: ‘Korean’}인코딩 결과를 보면 EUC-KR로 되어있는걸로 볼 수 있다.인코딩 형식 저장하기with open('./data/서울특별시교육청남산도서관 장서 대출목록 (2023년 06월).csv', encoding=\"EUC_KR\") as f: print(f.readline())위 방식으로 인코딩 형식을 따로 지정함으로써 파일을 읽어 올 수가 있다.read_csv()판다스에서 CSV을 읽어올때 사용하는 함수이다.import pandas as pddf = pd.read_csv('./data/서울특별시교육청남산도서관 장서 대출목록 (2023년 06월).csv', encoding=\"EUC-KR\", low_memory=False)low_memory=False로 해서 나누어 읽지 않고 한번에 읽는다. 하지만 low_memory를 사용하게 되면 한 번에 읽어오기 때문에 메모리 차지가 심하다. 이런 문제점을 보안하기 위해 사용하는 것이 dtype 매개변수로 데이터 타입을 지정하는 것이다.dtype은 각 열의 타입을 지정해주는 것으로 경고가 발생한 열에 타입을 정해 데이터 타입을 자동으로 찾지 않도록 한다.df = pd.read_csv('./data/서울특별시교육청남산도서관 장서 대출목록 (2023년 06월).csv', encoding=\"EUC-KR\", dtype={'ISBN': str, '세트 ISBN': str, '주제분류번호':str})to_csv()데이터프레임을 csv로 저장하는법df.to_csv('./data/test.csv')인덱스를 제거하여 저장할 수도 있다.df.to_csv('./data/test.csv', index =False)indexl_col 매개변수csv파일에 이미 index가 존재하면 index_col를 사용하여 추가되는 index를 제거한다. 저장된 test.csv파일에 첫번째 열에 인덱스가 존재하므로 index_col = 0 매개변수를 추가한다.df = pd.read_csv('./data/test.csv', index_col=0)판다스CSV파일 같은 텍스트 파일을 데이터프레임라는 표 형태로 저장해주는 것.시리즈1차원 배열을 생각해보자. 1차원 배열의 원소들은 모두 같은 타입을 가진다. 데이터프레임 구조를 보면 아래와 같은데2번째 행만 봐도 정수와 문자열이 섞여 있는구조로 이루어져있다. 데이터프레임은 열마다 다른 데이터타입을 사용할 수 있고, 각 열을 선택하면 이것을 시리즈 객체라고 한다.공개 데이터 세트국내 사이트 공공데이터 행정 안전부가 제공하는 공공데이터 통합 제공시스템 통합데이터 지도 국가와 민간분야에서 운영 중인 여러 빅데이터 플랫폼의 데이터를 한곳에서 검색할 수 있는 서비스 AI 허브 AI 통합 플랫폼으로 다양한 AI학습용 데이터를 제공 국가통계포털 경제, 사회, 환경 등 30개의 분야의 국내외 통계 데이터를 찾을 수 있음. 해외사이트 구글 데이터 세트 검색 무료로 사용할 수 있는 데이터를 제공하는 검색엔진 캐글 데이터 세트 머신러닝 경진 대회 플랫폼으로, 경진대회에서 사용한 데이터셋을 확인할 수 있다. 위키피디아 머신러닝데이터 세트 머신러닝 연구에 널리 사용되는 데이터 세트가 주제별로 정리되어 있다. 아마존 웹서비스 오픈데이터 UCI 머신러닝 데이터 저장소온라인포털 데이터 분석 커뮤니티 캐글 코리아 탠서플로 코리아 파이토치 코리아" }, { "title": "Tacotron2 작성법", "url": "/posts/tacotron2-writing/", "categories": "Project, tacotron2", "tags": "tacotron2, Project", "date": "2023-06-29 00:00:00 +0900", "snippet": "예시Tacotron2 및 Waveglow 모델은 torch.hub에서 가져온다. Tacotron2는 (“hello my world, i miss you”)와 같은 텍스트 입력을 주어지면 mel-spectrogram을 생성한다.Waveglow는 mel-spectrogram을 입력으로 음성을 생성한다.해당 정보는 audio.wav 파일로 저장된다.Package installpip install numpy scipy librosa unidecode inflect librosaapt-get updateapt-get install -y libsndfile1위 명령어를 차례대로 터미널에 입력한다.Tacotron2 loadTacotron2 모델을 불러오기 위해선 torch가 필요하다.import torchtacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')tacotron2 = tacotron2.to('cuda')tacotron2.eval()위 명령어를 입력하게 되면 LJ Speech dataset 에 데이터셋에서 사전 훈련된 Tacotron2를 불러올 수 있다.WaveGlow loadwaveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp16')waveglow = waveglow.remove_weightnorm(waveglow)waveglow = waveglow.to('cuda')waveglow.eval()위 명령어도 입력하면 사전 훈련된 WaveGlow모델을 불러올 수 있다.Utils loadutils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')sequences, lengths = utils.prepare_input_sequence([text])Input Texttext = \"hello my world, i miss you\"연결된 모델 실행with torch.no_grad(): mel_outputs_postnet, mel_lengths, alignments = tacotron2.infer(sequences, lengths) audio = waveglow.infer(mel)audio_numpy = audio[0].data.cpu().numpy()rate = 22050Audio 파일 저장from scipy.io.wavfile import writewrite(\"audio.wav\", rate, audio_numpy)최종 코드import torchfrom scipy.io.wavfile import writetacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp16')utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')tacotron2 = tacotron2.to('cuda')waveglow = waveglow.to('cuda')waveglow = waveglow.remove_weightnorm(waveglow)tacotron2.eval()waveglow.eval()text = \"hello my world, i miss you\"sequences, lengths = utils.prepare_input_sequence([text])with torch.no_grad(): mel_outputs_postnet, mel_lengths, alignments = tacotron2.infer(sequences, lengths) audio = waveglow.infer(mel)audio_numpy = audio[0].data.cpu().numpy()rate = 22050write(\"audio.wav\", rate, audio_numpy)InformationPytorch와Github를 참고해서 작성했다." }, { "title": "Tacotron2 추가", "url": "/posts/tacotron2-additional-explanation/", "categories": "Project, tacotron2", "tags": "tacotron2, Project", "date": "2023-06-28 00:00:00 +0900", "snippet": "Tacotron2Tacotron2는 mel-spectrograms를 예측하는 sequence-to-sequence 모델이다. 입력된 텍스트를 고정된 크기의 어떠한 방식으로 변환시키는 인코더와 디코더에서 사용할 정보를 인코더에서 추출하여 디코더에게 전달해주는 Attention과 전달된 것을 한 번에 하나의 Spectrogram으로 변환해주는 디코더로 이루어져있다.최종 Input은 text이고 output은 음성이다.하지만 앞서 말한것처럼 input으로 text가 들어와서 바로 음성을 생성하는것은 어려운 일이기 때문에 tacotron2에서는 TTS를 두 단계로 나누어 처리한다. Task1 : 텍스트로부터 mel-Spectrogram을 생성함 Task2 : mel-Spectrogram으로부터 음성을 합성함.Task1은 Tacotron2모델이 담당하고, Task2는 Vocoder로서 WaveNet모델을 변형해서 사용한다. 인코더 파란색 박스 디코더 주황색 박스전처리모델을 학습하기 위해서 input과 output이 한쌍으로 묶인 데이터가 필요하다.data/tts_datas/000001.wav|I love you.data/tts_datas/000002.wav|Nice to meet you.위와 같은 형태로 저장된 데이터중 텍스트는 character의 형태로 음성은 mel-spectrogram형태로 만들어줘야한다.우선 영어라면 띄어쓰기를 포함하여 알파벳을 나누는 작업을 한다 예를 들어 첫 번째 데이터 I love you의 텍스트는 ‘I’, ‘l’, ‘o’, ‘v’, … ,’u’ 형태로 변경되어 one-hot-encoding을 적용하여 정수열로 변경한 뒤 다음 모델의 input으로 적용된다. 한국어는 Tacotron2 해당 글을 확인하길 바란다.음성은 아직 이해를 하지 못하기도 했고 어려운부분이 있어서 일단 넘어가고 나중에 다시 다뤄보기로 하겠다.Encoder전처리를 통해 나온 Character타입 input을 총 3개의 단계를 걸쳐 `Encoded feature로 변환하는 역할을 한다.AttentionAttention은 매 시점마다 디코더에서 사용할 데이터를 인코더로부터 추출하여 가져오는 역할을 한다.DecoderAttention을 통해 얻은 데이터를 이전에 전처리 과정에서 생긴 mel-spectrogram을 이용하여 다음 시점의 mel-spectrogram을 생성하는 역할을 한다.Decoder은 총 4개의 단계를 거쳐서 진행된다.WaveGlowTacotron2 모델을 통해 encoder, attention, decoder과정을 거쳐 얻은 mel-spectrogram을 가지고 음성을 합성하는 모델이다.tacotron2 논문설명에서는 mel-spectrogram을 컨디셔닝을 사용하여 가우시안분포에서 오디오 샘플을 생성한다는데 무슨말인지는 잘 모르겠다.다음 할것Tacotron2을 코드로 작성해보고 tacotron2에 대해 추가로 공부해보자.참고Tacotron2 github" }, { "title": "BFS, DFS", "url": "/posts/dfs-bfs/", "categories": "algorithm, BFS_DFS", "tags": "algorithm, bfs, dfs", "date": "2023-06-26 00:00:00 +0900", "snippet": "1. Depth-First-Search최대한 깊게 내려간 뒤, 다시 내려갈 곳이 없으면 되돌아가서 다음 방향으로 이동.루트 혹은 다른 임의노드로부터 시작하여 다른 방향으로 넘어가기 전에 해당 방향을 완벽하게 탐색하는 방식.출처 : dfs 사진 Stack 혹은 재귀 함수를 통해 구현한다. 모든 노드를 탐색할 수 있음. bfs에 비해 간단함 속도는 느림. 작동방식Step1처음에는 Visited와 Stack 모두 비어있는 상태이다. 처음 노드는 0번째를 선택한다.Step20을 방문했으므로 Visited 배열에 0을 Push한다.그리고 0과 인접한 노드인 3, 2, 1를 Stack 배열에 Push한다.Step3그 다음 Stack의 0번째 노드인 1번노드를 방문한다.즉, Stack에는 pop을 하고 Visited에는 1노드를 push를 한다. 1에는 인접한 노드가 0밖에 없는데 0은 이미 Visited된 노드이기 때문에 따로 Stack에 추가한다.Step4다음으로 Stack에서 Pop을 하면 2가 나오고 그 2를 Visited에 push한다. 2에는 인접한 노드가 3, 4가 있는데 Stack에 이미 3이 존재하기 때문에 4만 push한다.Step5똑같이 4 노드를 Visited에 push하고 모든 인접 노드를 스택에 push한다.Step6Stack에 마지막 남은 3을 pop하고 visited에 push한다.이런식으로 DFS 순회가 진행된다.2. BFSRoot 노드 혹은 다른 임의의 노드부터 인접한 노드를 먼저 탐색하는 방법이다.출처 : bfs 사진 Queue 를 사용해서 구현한다. 최소비용 문제 간선의 가중치가 1이다. 정점과 간선의 개수가 적다( 시간제약, 메모리 제한 내의 만족한다.) 작동방식Step1root 노드인 1을 먼저 Visited 에 push를 하고 인접 노드인 2, 5, 3을 Queue에 enqueue한다.Step2다음 Queue에서 dequeue하여 2번노드를 visited하고 2번노드의 인접한 노드를 Queue에 enqueue한다.Step 3다른과정들도 마찬가지로 진행된다.Infomation해당 dfs, bfs를 보고 공부했다." }, { "title": "AWS Setting", "url": "/posts/aws_setting/", "categories": "Project, tacotron2", "tags": "tacotron2, Project, AWS", "date": "2023-06-26 00:00:00 +0900", "snippet": "AWSAWS(Amazon Web Services)란 Amazon.com에서 제공하는 ‘클라우딩 컴퓨터’이다.네트워킹을 기반으로 가상 컴퓨터와 스토리징 등 다양한 서비스를 누릴 수 있으며, 웹 서비스를 사용하여 기업이 애플리케이션 및 서비스를 쉽게 확장하고 실행할 수 있도록 해준다.클라이딩 컴퓨터컴퓨터 리소스를 인터넷을 통해 서비스로 사용할 수 있는 주문형 서비스이다. 직접 관리할 필요 없이 사용한만큼 비용만 지불하면 자유롭게 사용가능하다.간단하게 말하면 사용자가 대여 컴퓨팅 서비스를 요청하고 접근하는 클라우딩 플랫폼에 연결한다. 중앙서버는 클라이언트와 서버의 모든 통신을 처리하며 데이터 교환을 가능하게 한다.AWS Instance Create인스턴스 생성과 보안그룹 생성은 AWS 인스턴스 생성과AWS 보안그룹 생성을 보기를 권한다.AWS 연결1. EC2 인스턴스 연결임시 SSH키를 생성하여 인스턴스에 연결하는 방식자신의 인스턴스를 마우스에 올려 우클릭을 누른다.그러면 아래 사진처럼 나올탠데 여기서 연결을 눌러준다.;누르게되면 아래 사진처럼 나올 것이다.마찬가지로 연결을 눌러준다 사용자 이름에 ec2-user는 인스턴스를 시작할때 AMI에 정의된 사용자 이름으로 ssh로 연결시 ec2-user를 입력하여 연결한다.위와 같은 화면이 나오면 성공이다.2. ssh 연결이 방식은 ssh 키페어로 인증하는 방식이다. 이 방식을 사용하기 위해서는 보안그룹의 수정이 필요한데 ssh 보안그룹 설정를 참고해서 작성하면 된다.그 외 접속하는 방법은 putty를 이용한 접속 방법을 참고해서 해보자.AWS 환경설정apt-get update~$ sudo apt-get updatepython install~$ sudo apt-get upgrade python3~$ sudo apt install python3-pippip install플라스크 웹 어플리케이션을 만들기 위한 가상환경 설치~$ sudo apt-get install python3-virtualenvFLASK install~$ pip3 install Flask~$ python3 -m flask --vesionflask-ngork install~$ pip3 install flask-ngrokpython3-numpy install~$ sudo apt-get install python3-numpypyTorch~$ pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 [torch]는 홈페이지에 자세히 나와있음.권장드라이버 자동설치~$ sudo ubuntu-drivers autoinstall~$ pip3 install numpy scipy librosa unidecode inflect librosa내 PC -&gt; EC2에 파일을 업로드 하는법아래 명령어는 ec2에서 입력하는 것이 아닌 cmd에 입력하면 된다.scp -i [키위치] [파일명] [EC2 Host이름]@[EC2 Public ip]:[받는 위치]" }, { "title": "Chirpy에 utterances 댓글 연동하기", "url": "/posts/ufferance/", "categories": "Blog, ufferance", "tags": "blogging, guide", "date": "2023-06-21 00:00:00 +0900", "snippet": "사전 준비 Github 계정자신의 Gitblog설명우리가 사용하는 Chirpy는 Disqus를 기본적으로 지원한다.계정정보만 연동하면 잘 나오지만, 무료 기능들이 유로화되어 무료로 지원해주는 Utterances를 이용하여 댓글 기능을 만들어보자.Utterance 설치Utterance홈페이지에 접속하면 아래와 같은 사진이 나온다.오른쪽 위 install버튼을 클릭하여 설치를 진행한다.그러면 아래 사진 처럼 옵션이 두 개가 나오는데, 그중 Only select repositories버튼을 클릭한다.그 다음 자신의 Repository를 선택하고 install 버튼을 클릭한다.Configuration and Enable Utterancesinstall이 끝나면 홈페이지가 나오는데 아래로 내려보면, 중간에 Configuration 섹션이 나온다.여기에 나의 저장소를 입력하는 부분이 있는데 입력 형식은 [저장소ID]/[저장소명]이다.아래의 자신의 것을 입력한다.저는 yec3168/yec3168.github.io를 입력하였습니다.그 후 조금 더 내려보면 Enable Utterance섹션이 나온다.여기에 자바스크립트 섹션에서 repo에 적힌 주소가 자신의 저장소가 맞으면 이를 복사한다.Chirpy에 복사한 자바스크립트 입력아까 복사한 Scripts를 _layouts/post.html‘에 그대로 넣어준다. 위치는 파일 맨 아래에 추가한다.결과마지막으로 댓글 시스템이 각 post에 추가가 됐는지 확인해 보자.Ruby를 통해 로컬로 확인해보자http://127.0.0.1:4000문제 없이 잘 나오는것을 확인할 수 있고,Preview도 지원하는 것을 볼 수 있다.출처위 정보는 하얀눈길 와 jaejae0015블로그를 참고해서 만들어졌습니다." }, { "title": "Tacotron2", "url": "/posts/tacotron2/", "categories": "Project, tacotron2", "tags": "tacotron2, Project", "date": "2023-06-21 00:00:00 +0900", "snippet": "이번 산업협력프로젝트로 Tacotron2 아키텍처로 한국어 tts 시스템을 만드는 프로젝트를 하기로 했다.이번 프로젝트로 딥러닝, AWS, WEB 등 아직 배워보지 못한 부분도 많지만 차근차근 하나씩 배워가면서 해보도록 하겠다.타코트론먼저, Tacotron2 이란 17년도 구글이 논문에서제안한 Text-To-Speech 모델이다.TTS 아키텍쳐는 텍스트에서 Mel-Spectrogram을 생성하는 Mel-Network와 Mel-Spectrogram에서 Audio Signal을 생성하는 Vocoder로 이루어져있다. Mel-Spectrogram 음성데이터를 그대로 사용하면 파라미터도 많고 용량도 커져서 분석하기에 적합하지 않기 때문에, 이 음성 데이터를 mel scale로 볼 수 있게하여 주파수를 잘 인식하게 도와주는 것. NVIDIA Tacotron2TTS가 어려운점은 신호처리 개념이 많이 필요하기 때문이다. 음성처리 같은 경우는 librosa 라이브러리를 통해 Mel-Spectrogram같은 주파수뽑아서 바로 사용해도 성능에 크게 문제가 있지는 않지만 TTS 시스템은 좀 더 정교하게 뽑아줄 필요가 있다.이때 사용하는것이 NVIDIA Tacotron2이다. NVIDIA Tacotron2는 오픈소스로 학습 최적화를 잘 해놔서 학습속도도 빠르다는 장점이 있다.NIVIDIA Tacotron2 이 주소를 들어가면 자세히 볼 수 있다.NVIDIA Tacotron2 Data FormatNVIDIA Tacotron2는 아래와 같은 Data Format이 필요하다.data/tts_datas/000001.wav|튜닙은 자연어 처리 테크 스타트업입니다.data/tts_datas/000002.wav|타코트론은 대표적인 음성합성 모델이에요[오디오경로]|[텍스트] 를 |로 구분한 txt파일이 필요로하다.KoreanNIVIDIA Tacotron2의 구현체는 LS Speech를 제공한다.LS Speech는 영어 데이터셋이기 때문에 한국어 데이터 셋인 KKS를 사용하기 위해서는 수정이 필요하다.우리가 구현해 줘야할 함수는 `text_to_sequence 함수이다. 해당 함수는 매개변수로 어떠한 텍스트를 받아 토크나이징 및 숫자` 표현으로 인코딩해주는 역할이다.def text_to_sequence(text: str):\t...\t...print(text_to_sequence(\"안녕하세요\"))위 예시를 보면 text_to_sequence 함수에 안녕하세요 텍스트를 입력으로 받아 토크나이징 및 숫자로 표현해준다.text_to_sequence크게 3가지 기능을 수행한다. 텍스트 클리닝 토크나이징 숫자 표현으로 인코딩텍스트 클리닝어떤 문자열이 텍스트로 들어올지 모르기 때문에 허용 가능한 문자를 미리 정의해두는 것이다. 한국어로 TTS를 구현하려면 문자를 (초성, 중성, 종성)단위로 쪼개야한다.감이라는 문자는 ㄱ ㅏ ㅁ으로 쪼개야한다. NFKD Normalizeimport unicodedatatext = \"텍스트박스\"text = unicodedata.normalize('NFKD', text)for t in text: print(t, end=\" \")# ㅌ ㅔ ㄱ ㅅ ㅡ ㅌ ㅡ ㅂ ㅏ ㄱ ㅅ ㅡ위 방식으로 초성, 중성, 종성으로 분리가 가능하다.토크나이징 과 인코딩앞서 텍스트 클리닝으로 텍스트를 분해해 놨다.텍스트를 for문만 돌리면 쉽게 토크나이징이 가능하다.보통 토크나이징 하면서 인코딩도 같이 진행을 하는데, 인코딩을 하기 위해서는 Vocabulary를 먼저 정의해야합니다. 스페셜 토큰: _, ~ (pad, eos) 초성: 0x1100 ~ 0x1113 중성: 0x1161 ~ 0x1176 종성: 0x11A8 ~ 0x11C3 알파벳: ABCDEFGHIJKLMNOPQRSTUVWXYZ 숫자: 0123456789 특수문자: ?! (띄어쓰기 포함)" }, { "title": "Chirpy Markdown 사용법", "url": "/posts/how-to-write2/", "categories": "Blog, guide", "tags": "blogging, guide", "date": "2023-06-21 00:00:00 +0900", "snippet": "Information이 게시물은 Chirpy내용을 적은것이다.제목 heading&lt;h1 &gt;H1 - heading&lt;/h1&gt;&lt;h2 &gt;H2 - heading&lt;/h2&gt;&lt;h3&gt;H3 - heading&lt;/h3&gt;&lt;h4&gt;H4 - heading&lt;/h4&gt;H1 - headingH2 - headingH3 - headingH4 - headingListOrdered list1. Firstly2. Secondly3. Thirdly Firstly Secondly Thirdly Unordered list ```yaml Chapter Section Paragraph``` - Chapter + Section Paragraph 목록- [ ] Job + [x] Step 1 + [x] Step 2 + [ ] Step 3 Job Step 1 Step 2 Step 3 설명 목록태양: 지구가 공전하는 별달: 지구의 자연위성 태양 지구가 공전하는 별 달 지구의 자연위성Block Quote&gt; block quote 사용예시&gt; &gt; 두개도 가능 block quote 사용예시 두개도 가능 Prompts&gt; An example showing the `tip` type prompt.{: .prompt-tip }&gt; An example showing the `info` type prompt.{: .prompt-info }&gt; An example showing the `warning` type prompt.{: .prompt-warning }&gt; An example showing the `danger` type prompt.{: .prompt-danger } tip type prompt. info type prompt. warning type prompt. danger type prompt.Table|회사|나라||--|--|| 삼성 | 한국 ||회사|나라||–|–|| 삼성 | 한국 |Link&lt;http://127.0.0.1:4000&gt;http://127.0.0.1:4000Footnote덧붙이는 글Footnote를 클릭시 해당위치로 이동해준다.1후크[^footnote]2후크[^footnote]1후크[^footnote]2후크[^footnote]Inline code`Inline code`Inline codeFilepath파일 경로를 붙여준다.`/path/to/the/file.extend`{: .filepath}.Code blockcommoncode block특정 언어&lt;p&gt;안녕하세요&lt;/p&gt;수학MathJax에서 구동되는 수학$$ \\sum_{n=1}^\\infty 1/n^2 = \\frac{\\pi^2}{6} $$\\(\\sum_{n=1}^\\infty 1/n^2 = \\frac{\\pi^2}{6}\\) $ax^2 + bx + c = 0$$ax^2 + bx + c = 0$SVG```mermaid gantt title Adding GANTT diagram functionality to mermaid apple :a, 2017-07-20, 1w banana :crit, b, 2017-07-23, 1d cherry :active, c, after b a, 1d .``` gantt title Adding GANTT diagram functionality to mermaid apple :a, 2017-07-20, 1w banana :crit, b, 2017-07-23, 1d cherry :active, c, after b a, 1d" }, { "title": "Chirpy 게시글 작성 가이드", "url": "/posts/how-to-write/", "categories": "Blog, guide", "tags": "blogging, guide", "date": "2023-06-20 00:00:00 +0900", "snippet": "Information시작하기 앞서 아래 내용은 J1mmyson 의 블로그를 참고하여 공부함.파일 이름YYYY-MM-DD-TITLE.md 의 형식으로 파일을 만들어주고 _post/ 폴더에 넣어준다.위 사진 처럼 파일을 생성해주면 된다.Front Matter파일을 생성했으면, StackEdit이나 다른 편집기를 통해 파일을 열어 수정하면되는데 파일의 맨 처음은 아래와 같은 양식의 Front Matter을 작성해야한다.---title: TITLEdate: YYYY-MM-DD HH:MM:SS +/- TTTTcategories: [TOP_CATEGORIE, SUB_CATEGORIE]tags: [TAG]\t\t# TAG는 반드시 소문자--- title: 포스팅 제목 date : 날짜Categories : 최대 2개까지 등록 가능tags : 0~무한 개 까지 등록Table of ContentsTOC는 포스트 오른쪽 패널에 위치 하여 이기능을 끄고 싶다면 config.yml파일로가서 toc값을 false로 바꾸어주면된다. 하나의 Posting만 바꾸고 싶다면 아래 내용을 Front Matter에 추가하면된다.---toc: false---CommentsTOC와 마찬가지로 기능을 끄고 싶다면 config.yml파일로가서 comments값을 false로 바꾸어주면된다. 하나의 Posting만 바꾸고 싶다면 아래 내용을 Front Matter에 추가하면된다.---comments: false---MathematicsMathematics 기능은 기본적으로 꺼져 있으나 아래 코드를 추가하여 킬 수 있다.---math: true---MermaidMermaid는 표 생성 도구이다.---math: true---Images포스트 최상단에 이미지를 넣고 싶으면 아래와 같이 url를 추가하여 이미지를 넣을 수 있다.---image: /path/to/image-file---makedown을 통해 이미지를 넣는 방법![이미지 이름](/path/to/image)_Image Caption_이미지 캡션은 이미지 하단에 달리게 됨.Pin자신의 홈페이지 Home에 특정 게시물을 고정시킬수 있게 해주는 것.날짜가 최근일수록 위로 올라오게 된다.---pin: true---Code Block```를 통해 코드블럭을 생성가능하다.Information위 글은 J1mmyson 의 블로그를 참고하여 공부함." }, { "title": "시작", "url": "/posts/first-posting/", "categories": "Eungchan, Begin", "tags": "", "date": "2023-06-20 00:00:00 +0900", "snippet": "Github.io 블로그 시작하기.기존의 Velog를 통해 글을 올렸지만 Github blog를 보고 나도 해보고 싶다는 생각에 만들어보았다.앞으로 프로젝트, 자격증 공부, 개발일지 등 여러 글을 올릴 예정이다." } ]
